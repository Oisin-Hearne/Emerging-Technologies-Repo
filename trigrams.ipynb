{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd5b01d6",
   "metadata": {},
   "source": [
    "## Task 1 - Third-Order Letter Approximation Model\n",
    "\n",
    "The below code takes in all of the txt files in texts/, filtering out special & numerical characters, then counting how often each sequence of three characters appears and compiles it into a dictionary.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "35a30a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Global Variables\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "\n",
    "sanitizedTexts = []\n",
    "trigrams = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04846fe",
   "metadata": {},
   "source": [
    "### sanitizeText\n",
    "<hr>\n",
    "This function takes in a text file (ideally from Project Gutenberg), and cleans it up for use in a later function.\n",
    "This involves removing the pre and post amble, removing special characters, and multi-blank lines.\n",
    "The idea of this is to create text perfect for turning into trigrams - no niche special characters,\n",
    "no multi-blank lines flooding the trigrams with {\"\\n\\n\\n\"}, and no legalese from the Project Gutenberg postamble.\n",
    "\n",
    "Here are some of the more complex lines explained in more depth:\n",
    "\n",
    "This line takes the text and removes the Project Gutenberg pre and post amble. To accomplish this, \n",
    "the preamble and postamble variables are defined with the text at the end of the preamble, and the beginning of the postamble.\n",
    "Python's method of slicing (the : character between two indexes) **[3]** requires us to first find where in the string these characters are, which is why .index() is used. +len() is used to get to the end of the preamble, so that it isn't included.\n",
    "\n",
    "An example of how index and slicing works is below. .index() gets the index (that is, how far into the string the substring is) and slicing gets the substring between two indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c18b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('abcabcabc'.index('b')) # Result = 1.\n",
    "print('abc123abc'[3:6]) # Result = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762fe964",
   "metadata": {},
   "source": [
    "\n",
    "The result of the combination is an extraction of all of the text in between the preamble and postamble:\n",
    "\n",
    "\n",
    "```python\n",
    "    sanitizedText = (text[text.index(preamble)+len(preamble):text.index(postamble)]) # [3.1]\n",
    "```\n",
    "<hr>\n",
    "\n",
    "Now, we can move on to removing special characters and multi-blank lines. We can do this through Python Regex **[4]**, enabling us to set a \"filter\" for only the text we want to keep. This is what's being done in the first line:\n",
    "- re.sub means that we're replacing things that don't fit into our filter with the second string, empty in this case.\n",
    "- The [] designates a regex set, allowing us to define ranges of characters.\n",
    "- The ^ character is a complement - it means that we're substituing any characters that *don't* fit into our set.\n",
    "- a-zA-Z refers to all alphabetical lowercase & uppercase characters between A and Z.\n",
    "- \\\\s refers to spaces, . refers to periods, and \\n refers to new lines. These are the only sepcial characters we want to keep.\n",
    "\n",
    "So after running through this first line, any commas, colons or the like are removed from the string.\n",
    "\n",
    "```python\n",
    "    sanitizedText = re.sub(\"[^a-zA-Z\\\\s.\\n]\", \"\", sanitizedText) # [4.1]\n",
    "```\n",
    "\n",
    "The second line is more of the same - this time, it's looking for multiple instances of blank lines in a row. A lot of the Project Gutenberg books feature this, and if we allowed them into the Trigrams, we'd end up with a higher than average liklihood of the approximation generating 3 or 4 new lines after each line break.\n",
    "\n",
    "_r\"\\n\\s*\\n\"_ is a pattern looking for two new lines with nothing but spaces/new lines in between them - for example, if there were an instance of 3 new lines, one with a space in the middle, this would remove it and replace it with just one new line.\n",
    "\n",
    "We're subbing these examples with just one new line - we don't want our approximation to be all one blob of a line, so having some new lines is useful for making it look more like language.\n",
    "\n",
    "```python\n",
    "    sanitizedText = re.sub(r\"\\n\\s*\\n\", \"\\n\", sanitizedText) # [4.2]\n",
    "```\n",
    "<hr>\n",
    "\n",
    "Finally, our text is almost ready to be returned. We just have to perform some simple String Operations **[5]**, which Python handily provides. \n",
    "- .upper() converts all our text to uppercase, making the Trigrams more consistent later. \n",
    "- .strip() removes any leftover whitespace at the beginning/end of each text.\n",
    "\n",
    "```python\n",
    "    return sanitizedText.upper().strip()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "718545fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in a Project Gutenberg text and cleans it up for use in produceTrigrams\n",
    "# Removes preamble and postamble,\n",
    "def sanitizeText(text):\n",
    "    preamble = \" ***\" # Ending of the preamble\n",
    "    postamble = \"*** END OF \" # Beginning of the postamble.\n",
    "\n",
    "    # [3] Strips out the preamble and postamble from a text by\n",
    "    # creating a string in between the preamble and postamble variables.\n",
    "    sanitizedText = (text[text.index(preamble)+len(preamble):text.index(postamble)]) \n",
    "    sanitizedText = re.sub(\"[^a-zA-Z\\\\s.\\n]\", \"\", sanitizedText) # [4.1]\n",
    "    sanitizedText = re.sub(r\"\\n\\s*\\n\", \"\\n\", sanitizedText) # [4.2]\n",
    "\n",
    "    return sanitizedText.upper().strip() # Set to uppercase, and remove trailing/leading spaces. [5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9bb08b",
   "metadata": {},
   "source": [
    "### produceTrigrams\n",
    "<hr>\n",
    "This function takes in a list of our newly-sanitized texts and creates a dict of Trigrams, which end up looking something like:\n",
    "{\"ABC\": 123, \"DEF\": 342, ...} This tells us how often a set of three characters occurs in our text, which we can use later on to build our approximation.\n",
    "\n",
    "First we iterate over the texts with a for loop, then we *enumerate* over them **[6]**. This means we have a handy *counter* alongside our character while we go through each text. We'll need this for string indexes in a bit.\n",
    "\n",
    "```python\n",
    "    for text in texts:\n",
    "        for counter, c in enumerate(text)\n",
    "```\n",
    "\n",
    "\n",
    "Now we're going through every character in every text. We need to pull out three characters at a time. For example, \"THIS IS THE END\" would become \"THI\", \"HIS\", \"IS \" and so on. This can be done easily enough with slicing using our counter:\n",
    "\n",
    "```python \n",
    "    currentText = text[counter:counter+3]\n",
    "```\n",
    "\n",
    "This gives us three characters - the current character we're on, and the two following ones. This is the current effectively the current trigram. Now we just need to check something before adding it to our dictionary:\n",
    "If the trigram already exists in our dictionary, we just increment it's value. If we have \"ABC\": 1 and run into \"ABC\" again, we just get \"ABC\": 2. We should also be sure to check that the Trigram is actually three characters long - when reaching the end of the text, we may end up grabbing only one or two characters. We can cut these out here as we go.\n",
    "```python\n",
    "    if(len(currentText) < 3):\n",
    "        print(\"Found shorter trigram, \"+currentText+\", disregarding.\")\n",
    "    if(trigrams.get(currentText) != None): # If the trigram key already exists, increment it's value.\n",
    "        trigrams[currentText] = trigrams[currentText] + 1\n",
    "```\n",
    "\n",
    "If it doesn't yet exist, though, we'll need to initialize it. This is done like so - we just set it's value to 1.\n",
    "```python\n",
    "    else: # If the trigram hasn't been added to the dict yet, add it with the value of 1.\n",
    "        trigrams[currentText] = 1\n",
    "```\n",
    "\n",
    "After iterating through every character in every text, we now have a full dictionary of trigrams to return. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "14c09698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in a set of sanitized texts and turns them into a dictionary of trigrams, in the format {\"ABC\": 123}.\n",
    "def produceTrigrams(texts):\n",
    "    trigrams = {}\n",
    "\n",
    "    for text in texts:\n",
    "        for counter, c in enumerate(text): #Enumerate over the text, used to keep a counter of what character we're on. [6]\n",
    "            # text[counter:counter+3] gets 3 characters - the current one, and the two afterwards. [3]\n",
    "            # This basically gives us the \"current\" trigram.\n",
    "            currentText = text[counter:counter+3]\n",
    "            if(len(currentText) < 3):\n",
    "                print(\"Found shorter trigram, \"+currentText+\", disregarding.\")\n",
    "            elif(trigrams.get(currentText) != None): # If the trigram key already exists, increment it's value.\n",
    "                trigrams[currentText] = trigrams[currentText] + 1\n",
    "            else: # If the trigram hasn't been added to the dict yet, add it with the value of 1.\n",
    "                trigrams[currentText] = 1\n",
    "\n",
    "    return trigrams\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7493d48",
   "metadata": {},
   "source": [
    "### Getting our Trigrams Dict\n",
    "<hr>\n",
    "Now we have two functions for creating a dictionary of trigrams, we need to pull out some text from our files to use them.\n",
    "\n",
    "I used os.scandir() to achieve this, part of the OS library **[2]**. This let's us iterate over every file it finds in a certain folder (texts in this case).\n",
    "\n",
    "```python\n",
    "    for title in os.scandir(\"texts\"):\n",
    "```\n",
    "\n",
    "I'd like to be able to pull in everything from the /texts/ directory, but first I need to make sure they're all text files. To do this, I use another string operation - find(). This looks for the string \".txt\", and only opens up a file if it's present.\n",
    "\n",
    "```python\n",
    "    if((title.name.find(\".txt\")) != -1):\n",
    "```\n",
    "\n",
    "Now that we're sure the file is a text file, we can open() it **[1]**, enabling us to call read() on it, which pulls out the text content of the file. Then, we .close() the file for safety.\n",
    "Text is sanitized by the sanitizeText method as soon as it's read from .read(), and then added to a list for use later.\n",
    "\n",
    "```python\n",
    "    fileContent = open(title) # [1]\n",
    "    sanitizedTexts.append(sanitizeText(fileContent.read())) # Sanitize it & add it to the sanitizedTexts list.\n",
    "    fileContent.close()\n",
    "```\n",
    "\n",
    "Finally, once all the text files have been read, we can pass our newly created sanitizedTexts list into produceTrigrams, and get our dictionary.\n",
    "```python\n",
    "    trigrams = produceTrigrams(sanitizedTexts)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1f0f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for title in os.scandir(\"texts\"): # [2]\n",
    "    if((title.name.find(\".txt\")) != -1): # Only attempt to open + add the text file if it's a .txt\n",
    "        fileContent = open(title) # [1]\n",
    "        sanitizedTexts.append(sanitizeText(fileContent.read())) # Sanitize it & add it to the sanitizedTexts list.\n",
    "        fileContent.close()\n",
    "\n",
    "trigrams = produceTrigrams(sanitizedTexts)\n",
    "print(trigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4049ee20",
   "metadata": {},
   "source": [
    "## Task 2 - Third-Order Letter Approximation Generation\n",
    "\n",
    "The below code takes the list of trigrams and uses it to generate an approximation of english, deciding randomly weighted by the frequency of the next character, looking back at the previous two.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6b4727",
   "metadata": {},
   "source": [
    "First, we declare a current_string of \"TH\". These are the first two characters the approximation will use, as most texts start with these two characters in one way or another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f90686f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_string = \"TH\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1819a898",
   "metadata": {},
   "source": [
    "This is the loop where we generate the approximation, and it's doing a lot. It executes 10000 times to generate a text 10000 characters (incl whitespaces) long.\n",
    "\n",
    "The first line in the loop is a list comprehension, adapted from one meant to generate second-order approximations.\n",
    "List Comprehensions have an input, range and output and are used to easily iterate through lists, dictionaries and sets and perform some sort of operation on them.\n",
    "\n",
    "What the below one is doing is taking the trigrams (for x in trigrams.keys()) and checking for which ones have the same first two letters as the last two letters of the current_string (if x[0:2 == current_string[i:]]). The last character of the trigram is taken (which would be the potential next character of current_string), and then zipped up with its associated weight into the tris and weights variables.\n",
    "\n",
    "This gives us a list of the potential next characters as well as the weights for each of them, which we can use for the next line. This is done every loop - every character, we check what the last characters we generated were, and generate a list of potential next characters and weights.\n",
    "\n",
    "```python\n",
    "    tris, weights = list(zip(*[(x[2], trigrams[x]) for x in trigrams.keys() if x[0:2] == current_string[i:]]))\n",
    "```\n",
    "\n",
    "<hr>\n",
    "\n",
    "Now we need to actually add the next character to the current string. This is done using random.choices, which takes in the list of potential next characters, and their respective weights.\n",
    "\n",
    "The below line may look as bulky as the last one, but it's actually much simpler. ''.join simply means that we're appending whatever character we generate, not replacing anything. We need to pass this two strings: one of them being the current one, and the other being our randomly generated character. \n",
    "\n",
    "This is where random.choices comes in. We pass it the tris, weights, and a population (how many things to generate) of 1. Because this generates as a list, we also need to give it a [0] to tell it that we only want the first value from it (which will also be the only one, as it has a population of 1).\n",
    "\n",
    "```python\n",
    "    current_string = ''.join([current_string, (random.choices(list(tris), weights=weights, k=1)[0])])\n",
    "```\n",
    "\n",
    "Once this has run (it may take about 30ish seconds due to some inefficiency), current_string will contain a 10000 character long approximation of the english language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c12d8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10001):\n",
    "    tris, weights = list(zip(*[(x[2], trigrams[x]) for x in trigrams.keys() if x[0:2] == current_string[i:]])) # [7]\n",
    "    current_string = ''.join([current_string, (random.choices(list(tris), weights=weights, k=1)[0])]) # [7]\n",
    "\n",
    "print(current_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0571f385",
   "metadata": {},
   "source": [
    "## Task 3 - Analyze The Model\n",
    "\n",
    "Now we need to see how effective our model is. To do this, we figure out what % of the words generated are real words by comparing it to a list.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58be66f1",
   "metadata": {},
   "source": [
    "First, we open up the words.txt file provided. We just need to read this in, and split it up into a list we can compare our approximation to. We can close the file when we're done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e3e7a37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_file = open(\"words.txt\", \"r\")\n",
    "words_list = words_file.read().split(\"\\n\") # Read the file and split it up by line into a list.\n",
    "words_file.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203ad2e5",
   "metadata": {},
   "source": [
    "Next, we create approx_words by splitting up our approximation (stored in current_string).\n",
    "\n",
    "\n",
    "Then we can move on to our loop to check the accuracy of our approximation, which is actually relatively simple. We create a correct_words and set it at 0, which we'll use to measure how well the approximation holds up. Then, we just loop over every word in approx_words and check if it's in words_list. If it is, we can increment correct_words by 1. This gives us the number of words that are found in both - the number of words that are real english."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0f0aac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "approx_words = current_string.split() # Handily, .split() by default handles all forms of whitespace. [5]\n",
    "\n",
    "correct_words = 0\n",
    "\n",
    "for word in approx_words: # Check every word in the approximation against the words list, and increment correct_words if correct.\n",
    "    if word in words_list:\n",
    "        correct_words = correct_words + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d37511",
   "metadata": {},
   "source": [
    "Now we can measure the percentage of real words in our approximation by doing correct_words/len(approx_words)*100. I rounded this to two decimal places for readability. From running it a few times, this usually ranges from about 35-38% english words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6614d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage = round(((correct_words/len(approx_words))*100), 2)\n",
    "print(percentage, \"% real words.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dc2df3",
   "metadata": {},
   "source": [
    "## Task 4 - Export Model\n",
    "Finally, we export the model using python's json library.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a44283",
   "metadata": {},
   "source": [
    "This final part is very simple - all we do is open the trigrams.json file, write to it, and close it again.\n",
    "\n",
    "I used the json.dumps() function to output to json in a readable format, which takes in the trigrams model. It's also sorted and indented to organise it a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ddb05fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonFile = open(\"trigrams.json\", \"w\")\n",
    "jsonFile.write(json.dumps(trigrams, sort_keys=True, indent=3)) #[8]\n",
    "jsonFile.close"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aa8b30",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b1d09f",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [1] - Reading text files in Python: https://www.w3schools.com/python/python_file_open.\n",
    "- [2] - Using Python's OS Module: https://www.geeksforgeeks.org/how-to-iterate-over-files-in-directory-using-python/\n",
    "- [3] - Slicing text in Python: https://python-reference.readthedocs.io/en/latest/docs/brackets/slicing.html\n",
    "    - [3.1] - Finding a string between two substrings (used for removing Pre/Postamble): https://stackoverflow.com/a/51456576\n",
    "- [4] - Python Regex Library Docs: https://docs.python.org/3/library/re.html\n",
    "    - [4.1] - Using regex in Python: https://www.w3schools.com/python/python_regex.asp\n",
    "    - [4.2] - Removing multi-blank lines in a text: https://stackoverflow.com/a/28902081\n",
    "- [5] - Python String Methods: https://docs.python.org/3.4/library/stdtypes.html#string-methods\n",
    "- [6] - Python enumerator/counter: https://docs.python.org/3/library/functions.html#enumerate\n",
    "- [7] - Second Order Approximation Method from Notes: https://github.com/ianmcloughlin/2425_emerging_technologies/blob/main/02_language_models.ipynb\n",
    "- [8] - Python JSON Library Documentation: https://docs.python.org/3/library/json.html\n",
    "\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
